diff --git a/R/eval_functions.R b/R/eval_functions.R
index fb4707c..eb40c8d 100644
--- a/R/eval_functions.R
+++ b/R/eval_functions.R
@@ -34,16 +34,28 @@ parse_model_configs <- function(yaml_path) {
         ))
       }
 
+      # Validate release_date format (YYYY-MM-DD)
+      if (!is.null(model$release_date)) {
+        release_date_str <- as.character(model$release_date)
+        if (!grepl("^\\d{4}-\\d{2}-\\d{2}$", release_date_str)) {
+          stop(glue(
+            "Model '{model$name}' has invalid release_date format: '{release_date_str}'. Expected YYYY-MM-DD."
+          ))
+        }
+      }
+
       # Build config with defaults for optional fields
       config <- list(
         name = model$name,
         model_id = model$model_id,
         api_model_id = model$api_model_id,
         provider = model$provider,
+        release_date = model$release_date,
         thinking = model$thinking %||% FALSE,
         thinking_budget = model$thinking_budget %||% 2000,
         base_url = model$base_url %||% NULL,
-        api_key_env = model$api_key_env %||% NULL
+        api_key_env = model$api_key_env %||% NULL,
+        api_args = model$api_args %||% NULL
       )
 
       config
diff --git a/R/helpers.R b/R/helpers.R
index 72b749b..6b4327b 100644
--- a/R/helpers.R
+++ b/R/helpers.R
@@ -51,6 +51,9 @@ compute_summary_stats <- function(
       model_info |> select(model_join, provider),
       by = "model_join"
     ) |>
+    mutate(
+      usd_per_correct = if_else(correct == 0, NA_real_, price / correct)
+    ) |>
     arrange(desc(percent_correct))
 }
 
@@ -173,6 +176,58 @@ plot_cost_vs_performance <- function(summary_data) {
     )
 }
 
+#' Create efficiency bar chart (Cost per Correct Answer)
+#'
+#' @param summary_data Summary statistics with usd_per_correct and provider columns
+#' @return ggplot object
+plot_efficiency <- function(summary_data) {
+  # Filter out NA values and prepare data
+  plot_data <- summary_data |>
+    filter(!is.na(usd_per_correct)) |>
+    mutate(
+      model_display = fct_reorder(model_display, usd_per_correct)
+    )
+
+  if (nrow(plot_data) == 0) {
+    return(
+      ggplot() +
+        annotate(
+          "text",
+          x = 0.5,
+          y = 0.5,
+          label = "No models with correct answers to display",
+          size = 6
+        ) +
+        theme_void()
+    )
+  }
+
+  ggplot(plot_data, aes(x = usd_per_correct, y = model_display, fill = provider)) +
+    geom_col() +
+    scale_fill_manual(
+      values = c(
+        "Anthropic" = "#be8bd4ff",
+        "OpenAI" = "#80c8d3ff",
+        "Google" = "#f6e8c3"
+      )
+    ) +
+    scale_x_continuous(labels = label_dollar()) +
+    labs(
+      x = "Cost per Correct Answer (USD)",
+      y = NULL,
+      fill = "Provider"
+    ) +
+    theme_light() +
+    theme(
+      legend.position = "bottom",
+      plot.margin = margin(10, 10, 10, 10),
+      axis.title = element_text(size = 14),
+      title = element_text(size = 16),
+      axis.text = element_text(size = 12),
+      legend.text = element_text(size = 12)
+    )
+}
+
 # Table Functions ------------------------------------------------------------
 
 #' Create pricing and performance table
@@ -191,6 +246,7 @@ create_pricing_table <- function(summary_data, model_info) {
       `Input Tokens Used` = input,
       `Output Tokens Used` = output,
       `Total Cost` = price,
+      `Cost / Correct` = usd_per_correct,
       `% Correct` = percent_correct
     ) |>
     gt::gt() |>
@@ -198,7 +254,8 @@ create_pricing_table <- function(summary_data, model_info) {
       columns = c(
         `Input (per 1M tokens)`,
         `Output (per 1M tokens)`,
-        `Total Cost`
+        `Total Cost`,
+        `Cost / Correct`
       ),
       currency = "USD",
       decimals = 2
diff --git a/app.R b/app.R
index 2ce895a..23648d6 100644
--- a/app.R
+++ b/app.R
@@ -120,6 +120,16 @@ ui <- page_navbar(
           )
         ),
 
+        nav_panel(
+          "Efficiency",
+          card(
+            card_header("Cost per correct answer (lower is better)"),
+            card_body(
+              plotOutput("efficiency_plot", height = "600px")
+            )
+          )
+        ),
+
         nav_panel(
           "Pricing Details",
           card(
@@ -225,6 +235,13 @@ server <- function(input, output, session) {
     plot_cost_vs_performance(eval_summary())
   })
 
+  # Efficiency plot (Cost per Correct Answer)
+  output$efficiency_plot <- renderPlot({
+    req(nrow(eval_summary()) > 0)
+
+    plot_efficiency(eval_summary())
+  })
+
   # Pricing table
   output$pricing_table <- render_gt({
     req(nrow(eval_summary()) > 0)
diff --git a/eval/run_eval.R b/eval/run_eval.R
index b47ce9e..38f960d 100644
--- a/eval/run_eval.R
+++ b/eval/run_eval.R
@@ -2,32 +2,189 @@
 # Will skip models that have already been run (by looking in results_rds)
 # Combines all rds results into data/data_combined.rds
 
-library(ellmer)
-library(vitals)
-library(purrr)
+# ============================================================================
+# CLI Argument Parsing (base R only, no external dependencies)
+# ============================================================================
+
+print_usage <- function() {
+  cat("Usage: Rscript run_eval.R [options]
+
+Options:
+  --help              Print this help message and exit
+  --yaml <path>       Path to models YAML file (default: data/models.yaml)
+  --results-dir <path> Directory for results RDS files (default: results_rds)
+  --list-models       Print available models and exit
+  --dry-run           Print models to evaluate without running, then exit
+  --only <ids>        Comma-separated list of model IDs to consider
+
+Examples:
+  Rscript run_eval.R --help
+  Rscript run_eval.R --list-models
+  Rscript run_eval.R --dry-run
+  Rscript run_eval.R --only sonnet_4,opus_4_5
+  Rscript run_eval.R --yaml custom_models.yaml --results-dir custom_results
+")
+}
+
+# Parse command line arguments
+args <- commandArgs(trailingOnly = TRUE)
+
+# Default values
+yaml_path_arg <- NULL
+results_dir_arg <- NULL
+list_models_flag <- FALSE
+dry_run_flag <- FALSE
+only_models <- NULL
+
+i <- 1
+while (i <= length(args)) {
+  arg <- args[i]
+
+  if (arg == "--help") {
+    print_usage()
+    quit(status = 0)
+  } else if (arg == "--yaml") {
+    if (i + 1 > length(args)) {
+      stop("--yaml requires a path argument")
+    }
+    yaml_path_arg <- args[i + 1]
+    i <- i + 2
+  } else if (arg == "--results-dir") {
+    if (i + 1 > length(args)) {
+      stop("--results-dir requires a path argument")
+    }
+    results_dir_arg <- args[i + 1]
+    i <- i + 2
+  } else if (arg == "--list-models") {
+    list_models_flag <- TRUE
+    i <- i + 1
+  } else if (arg == "--dry-run") {
+    dry_run_flag <- TRUE
+    i <- i + 1
+  } else if (arg == "--only") {
+    if (i + 1 > length(args)) {
+      stop("--only requires a comma-separated list of model IDs")
+    }
+    only_models <- strsplit(args[i + 1], ",")[[1]]
+    i <- i + 2
+  } else {
+    stop(paste("Unknown argument:", arg, "\nUse --help for usage information."))
+  }
+}
+
+# ============================================================================
+# Load Libraries (after CLI parsing to allow --help without dependencies)
+# ============================================================================
+
+library(yaml)
+library(fs)
 library(glue)
+library(purrr)
+library(dplyr)
 
 # Source helper functions
 source(here::here("R/task_definition.R"))
 source(here::here("R/data_loading.R"))
 source(here::here("R/eval_functions.R"))
 
+# ============================================================================
 # Configuration
-YAML_PATH <- here::here("data/models.yaml")
-RESULTS_DIR <- here::here("results_rds")
+# ============================================================================
+
+YAML_PATH <- if (!is.null(yaml_path_arg)) {
+  yaml_path_arg
+} else {
+  here::here("data/models.yaml")
+}
+
+RESULTS_DIR <- if (!is.null(results_dir_arg)) {
+  results_dir_arg
+} else {
+  here::here("results_rds")
+}
+
 LOG_DIR <- here::here("logs")
 SCORER_MODEL <- "claude-3-7-sonnet-latest"
 
-# Set up logging
-vitals::vitals_log_dir_set(LOG_DIR)
+# ============================================================================
+# Handle --list-models
+# ============================================================================
+
+if (list_models_flag) {
+  model_configs <- parse_model_configs(YAML_PATH)
+
+  # Print TSV header
+  cat("model_id\tname\tprovider\trelease_date\tapi_model_id\n")
+
+  # Print each model
+  for (model_id in names(model_configs)) {
+    cfg <- model_configs[[model_id]]
+    cat(sprintf(
+      "%s\t%s\t%s\t%s\t%s\n",
+      model_id,
+      cfg$name,
+      cfg$provider,
+      if (!is.null(cfg$release_date)) as.character(cfg$release_date) else "",
+      cfg$api_model_id
+    ))
+  }
+
+  quit(status = 0)
+}
+
+# ============================================================================
+# Handle --dry-run
+# ============================================================================
+
+if (dry_run_flag) {
+  model_configs <- parse_model_configs(YAML_PATH)
+
+  # Filter by --only if specified
+  if (!is.null(only_models)) {
+    valid_ids <- intersect(only_models, names(model_configs))
+    if (length(valid_ids) == 0) {
+      message("No valid model IDs found in --only list")
+      quit(status = 0)
+    }
+    model_configs <- model_configs[valid_ids]
+  }
+
+  unevaluated <- find_unevaluated_models(model_configs, RESULTS_DIR)
+
+  if (length(unevaluated) == 0) {
+    message("No models to evaluate. All models have existing results.")
+  } else {
+    message(glue("Would evaluate {length(unevaluated)} model(s):"))
+    for (mid in unevaluated) {
+      message(glue("  - {mid}"))
+    }
+  }
+
+  quit(status = 0)
+}
 
 # ============================================================================
-# Run Evaluation
+# Run Evaluation (requires API keys)
 # ============================================================================
 
+library(ellmer)
+library(vitals)
+
+# Set up logging
+vitals::vitals_log_dir_set(LOG_DIR)
+
 # Parse YAML configuration
 model_configs <- parse_model_configs(YAML_PATH)
 
+# Filter by --only if specified
+if (!is.null(only_models)) {
+  valid_ids <- intersect(only_models, names(model_configs))
+  if (length(valid_ids) == 0) {
+    stop("No valid model IDs found in --only list")
+  }
+  model_configs <- model_configs[valid_ids]
+}
+
 # Find unevaluated models
 unevaluated <- find_unevaluated_models(model_configs, RESULTS_DIR)
 
